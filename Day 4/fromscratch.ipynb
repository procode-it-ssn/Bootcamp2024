{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "KfaLs_h6RfJd",
        "xMOpQnGUTmGg",
        "feECXG14ZX1Q",
        "GoxGanhdcyil",
        "RFqjXyPDdY9G",
        "YFNRqHMafyRv",
        "EGufYAUJgrmY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulakrishnanbalaji/ProCode-Kaggle/blob/main/Copy_of_ProCode_ML_starter_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Competition website: [Kaggle competition link](https://www.kaggle.com/competitions/playground-series-s4e1/)"
      ],
      "metadata": {
        "id": "ioctzKlgLBGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -O train.csv https://raw.githubusercontent.com/gokulakrishnanbalaji/ProCode-Kaggle/main/train.csv\n",
        "! wget -O test.csv https://raw.githubusercontent.com/gokulakrishnanbalaji/ProCode-Kaggle/main/test.csv\n",
        "! wget -O sample_submission.csv https://raw.githubusercontent.com/gokulakrishnanbalaji/ProCode-Kaggle/main/sample_submission.csv"
      ],
      "metadata": {
        "id": "vUAXKGvTpuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "EXVe5QfUJ-I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "_7jjl138J-_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Z2wj0rqAyrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration and analysis"
      ],
      "metadata": {
        "id": "JNLl6jG-KNsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "train_data = pd.read_csv('/content/train.csv')\n",
        "test_data = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "jRH7P7FdKKfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the first few rows\n",
        "# train_data.head()\n",
        "train_data.info()\n",
        "train_data.describe()"
      ],
      "metadata": {
        "id": "q6D8r3UEKVoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of df\n",
        "train_data.shape"
      ],
      "metadata": {
        "id": "SYxkB8ZgKYQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for null values\n",
        "train_data.isna().any()"
      ],
      "metadata": {
        "id": "7K5LAheCMnlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify unwanted column and remove them in both train and test\n",
        "train_data=train_data.drop(['id','CustomerId','Surname'],axis=1)\n",
        "y_id = test_data['id']\n",
        "test_data = test_data.drop(['id','CustomerId','Surname'],axis=1)"
      ],
      "metadata": {
        "id": "U5Dl77zCNV9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check for duplicates\n",
        "train_data.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "wiI2j3m_N8vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the duplicates\n",
        "train_data=train_data.drop_duplicates()\n",
        "train_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "DoJnNOtpOSxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate numerical and categorical data\n",
        "num_train_data = train_data.select_dtypes(include=np.number)\n",
        "cat_train_data = train_data.select_dtypes(exclude = np.number)"
      ],
      "metadata": {
        "id": "T_KbYxqsPf8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check correlation among numerical data cols\n",
        "corr = num_train_data.corr()\n",
        "corr\n"
      ],
      "metadata": {
        "id": "d3l2KdaOQULs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "KfaLs_h6RfJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode for categorical variable for train and test\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "for columns in cat_train_data.columns:\n",
        "    labelencoder.fit(train_data[columns])\n",
        "    train_data[columns]=labelencoder.transform(train_data[columns])\n",
        "    test_data[columns]=labelencoder.transform(test_data[columns])\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "OoxfFq7QQuAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature engineering"
      ],
      "metadata": {
        "id": "xMOpQnGUTmGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new col called balance_per_salary\n",
        "train_data['balance_per_salary']=train_data['Balance']/train_data['EstimatedSalary']\n",
        "test_data['balance_per_salary']=test_data['Balance']/train_data['EstimatedSalary']\n",
        "# train_data = train_data.drop(columns=['Balance','EstimatedSalary'])\n",
        "train_data\n",
        "test_data"
      ],
      "metadata": {
        "id": "QOPWMJufSq4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features in both train and test data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "maxminscaler = MinMaxScaler()\n",
        "\n",
        "for col in train_data.columns:\n",
        "    if col != 'Exited':\n",
        "        maxminscaler.fit(train_data[[col]])\n",
        "        train_data[col] =maxminscaler.transform(train_data[[col]])\n",
        "        test_data[col] =maxminscaler.transform(test_data[[col]])"
      ],
      "metadata": {
        "id": "yHG1zZLJX7iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data.head()\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "QhgYFiFHOEfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection"
      ],
      "metadata": {
        "id": "feECXG14ZX1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data as train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "y=train_data['Exited']\n",
        "x=train_data.drop(columns=['Exited'])\n",
        "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.33,random_state=72)\n",
        "print(train_x.shape)\n",
        "test_x.shape"
      ],
      "metadata": {
        "id": "BDHRpb2VZYq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we will train with logistic regression and XGboost"
      ],
      "metadata": {
        "id": "dP5YFqlRZ1u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_x,train_y)\n",
        "logreg_ypred = logreg.predict(test_x)\n",
        "\n"
      ],
      "metadata": {
        "id": "YuQqoBCjaBun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use xgboost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(train_x,train_y)\n",
        "xgb_ypred = xgb.predict(test_x)\n"
      ],
      "metadata": {
        "id": "sec4Vap_azwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "GoxGanhdcyil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score for logistic regression\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score(test_y,logreg_ypred)\n"
      ],
      "metadata": {
        "id": "2vBfe7LSb1xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score for XGBoost\n",
        "\n",
        "#from sklearn.metrics import f1_score\n",
        "f1_score(test_y,xgb_ypred)"
      ],
      "metadata": {
        "id": "bZ4b4fUGdEHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "RFqjXyPDdY9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tweak the parameters n_estimators, max_depth ,learning_rate\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "paramdict={'n_estimators':[50,100], 'max_depth':[2,5] ,'learning_rate':[0.1,0.01]}\n",
        "gridsearch = GridSearchCV(estimator=xgb,param_grid=paramdict,cv=5)\n",
        "gridsearch.fit(train_x,train_y)\n",
        "xgb_gsv_ypred=gridsearch.predict(test_x)\n"
      ],
      "metadata": {
        "id": "hrlGoLacdLKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f1 score for the grid_search\n",
        "f1_score(test_y,xgb_gsv_ypred)\n"
      ],
      "metadata": {
        "id": "wDipI2Q-edXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Report"
      ],
      "metadata": {
        "id": "YFNRqHMafyRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_y,xgb_gsv_ypred)\n"
      ],
      "metadata": {
        "id": "5t33Vu0LfcQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # ROC Curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_y,xgb_gsv_ypred)\n",
        "\n",
        "# Compute Area Under the ROC Curve (AUC)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "larzYEqSgF2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "EGufYAUJgrmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions using the latest model\n",
        "y_pred  = gridsearch.predict(test_data)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "P-iIZEVVgugN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make submission dataframe\n",
        "y_pred = pd.DataFrame(y_pred,columns=['Exited'])\n",
        "y_pred['id']=y_id\n",
        "y_pred"
      ],
      "metadata": {
        "id": "sWd4To1gg8cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert submission to csv\n",
        "y_pred.to_csv('submission.csv',index=False)\n"
      ],
      "metadata": {
        "id": "2svox_vphfaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoOs-5Xxhm7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}